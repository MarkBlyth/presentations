#+OPTIONS: H:2 toc:nil
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: UoB
#+AUTHOR: Mark Blyth
#+TITLE: /(More)/ surrogate modelling
#+DATE: [2020-06-08 Mon]

* Background
** Week's goal
Keep working through different regression models:
\vfill
    * *Function-space distribution over kernels*
    * *Matern kernels*
    * *Bayesian free-knot splines*
    * +Generalised spectral mixture kernels+
    * Switching kernel
    * NARMAX 
    * Neural ODEs 

** Week's goal
    * *Function-space distribution over kernels*
      * Works, but no better than the other stationary kernels /[why not?]/
    * *Matern kernels*
      * Works, but doesn't average noise out /[lengthscale issue]/
    * *Bayesian free-knot splines*
      * Works well!
    * +Generalised spectral mixture kernels+
      * Couldn't get them to train


* Matern kernel
** Matern kernel
   * SEKernel is \(C^\infty\) smooth
   * Matern kernel generalises this to arbitrary degrees of smoothness
   * Matern \(\frac{3}{2}\) and \(\frac{5}{2}\) are most commonly used
     * Once- and twice- differentiable posteriors
   * Lack of smoothness adds more flexibility
   * Quick and easy to test!

** Can sometimes smooth data
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Hindmarsh-Rose fast
#+END_CENTER    

#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern1.pdf]]

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Hindmarsh-Rose fast
#+END_CENTER    

#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern2.pdf]]

** ...but not always
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Hodgkin-Huxley
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern4.pdf]]

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Hodgkin-Huxley
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern3.pdf]]

** ...but not always
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Real data
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern5.pdf]]

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
Real data
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./Matern6.pdf]]


* MSPEs
** MSPEs
Exactly how good are any fits?
\vfill
   * Mean-square prediction error can quantify the goodness-of-fit with synthetic data
     * Split synthetic data into test and training
     * Fit model on training data
     * Find prediction error from test data
       
\vfill

The downsampling step causes problems with a GPR fit
     
** Model fits
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
   
*** Downsampled, 333 datapoints :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
#+BEGIN_CENTER
Downsampled 666 to 333 datapoints
#+END_CENTER
#+ATTR_LATEX: :width 1.1\textwidth
[[./downsample333.pdf]]

*** Simulated with 348 datapoints :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

#+BEGIN_CENTER
Simulated with 348 datapoints
#+END_CENTER
#+ATTR_LATEX: :width 1.1\textwidth
[[./nodownsample.pdf]]

** MSPEs
Validation results can't always be trusted - MSPE values are often too high.
Possible hand-wavy explanation:
#+ATTR_LATEX: :overlay [<+->]
    * More datapoints were generated by tightning the ODE solver tolerance
    * ODE solvers use an adaptive stepsize
      * More datapoints where the system is locally stiff
      * Datapoints are therefore chosen to be as informative as possible
      * Placed at points with the largest margin for error, to zero this error
    * Changing /rtol/ always gives a maximally informative dataset, for the number of points
    * Downsampling doesn't always give maximally informative data
      * Removes datapoints based on their indices, rather than informativeness
    * Less informative dataset means worse GPR fit

** Fixing MSPE
Alternative approaches to MSPE:
       * Leave-one-out cross validation 
         * Computationally expensive
       * Visual inspection
	 * Subjective, imprecise
       * Run two solvers, one for test and one for training data
	 * Need to make sure there's no shared datapoints for this to work
	 * Bad test if test and training points are very close to each other
\vfill
MSPE only seems to break on PeriodicKernels or Hodgkin Huxley dataset
    * Chosen approach: use MSPE as-is, but do it carefully

** Real data
    * Real data is the best test of a regression model
    * Lack of ground-truth makes it harder to evaluate models on real data
    * A heuristic method:
      * Fit model
      * Look at the model fit
      * Find residuals
      * Look at their distribution

** Real data, splines model

#+ATTR_LATEX: :width .9\textwidth
[[./hist.pdf]]
\vfill

** Real data
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
#+ATTR_LATEX: :width \textwidth
[[./hist.pdf]]

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

    * Nothing particularly alarming about the residuals
      * That's all we can really say
    * +H_0: residuals are Gaussian+ /*[rejected]*/
	* Shapiro-Wilk p-value: 3.0734860972720244e-21
	* D'Agostino's K^2 test: 4.3027710773715154e-37

** Calculated MSPEs


|-----------------+------------+------------+----------+----------------|
| Model           |   Matern32 | Matern52   | SEKernel | PeriodicKernel |
|-----------------+------------+------------+----------+----------------|
| Hodgkin Huxley  | *2.26(-2)* | 2.67e-1    |     5.57 |           9.25 |
| Fitzhugh Nagumo |    5.37e-7 | *2.34(-8)* |  2.97e-4 |        2.21e-2 |
| HRFast          |    1.48e-7 | *4.30(-9)* |  2.37e-6 |        1.22e-2 |
|-----------------+------------+------------+----------+----------------|

    * Calculated on noise-free models
    * Matern kernels perform the best
    * Can't compare MSPEs across neuron models, since it scales with the square of signal amplitude

** Calculated MSPEs
|-----------------+----------+-----------+-----------+----------------|
| Model           | Matern32 |  Matern52 |  SEKernel | PeriodicKernel |
|-----------------+----------+-----------+-----------+----------------|
| Hodgkin Huxley  |   *6.64* |      8.57 |      24.6 |            150 |
| Fitzhugh Nagumo |  3.95e-3 | *3.80e-3* |   4.85e-3 |        2.85e-2 |
| HRFast          |  1.17e-2 |   1.16e-2 | *1.11e-2* |        2.18e-2 |
|-----------------+----------+-----------+-----------+----------------|

    * Calculated on noise-perturbed models
    * Matern kernels are generally good
    * Representative values only; should really be ran lots of times to get an average


* Splines vs GPR
** Splines
#+ATTR_LATEX: :overlay [<+->]
    * `Tie' together pieces of polynomials at knot-points
    * Lower degree-of-freedom than GPR, so they forcibly remove noise /[see later slide]/
    * No stationarity assumptions
      * Can account for varying lengthscales by placing more knots at fast-changing points
    * Successful splining needs good choices of knots
	* Too many or too few knots will give bad results
	* Poorly placed knots will mean splines can't capture signal
    * Can choose degree of smoothness, for smoothing splines
	* Downside: no good way to choose this!


** Free-knot splines 
A clever approach: free-knot splines
#+ATTR_LATEX: :overlay [<+->]
    * Automatically choose both location and number of knots
    * A GPR paper said free-knot splines work well
    * Current splines method: Bayesian adaptive regression splines 
      * Also called BARS, Bayesian free-knot splines
    * There's a few free-knot splines methods out there
    * I don't know how they work...


** Splines vs GPR
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

#+BEGIN_CENTER
Splines
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./BARS.pdf]]
    


***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

#+BEGIN_CENTER
GPR (SEKernel)
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./SEKernel_f_6d23e2_l_5d71e-8_n_0d1.pdf]]


** Splines vs GPR
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

#+BEGIN_CENTER
Splines
#+END_CENTER
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./BARS2.pdf]]    
    

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+BEGIN_CENTER
GPR (SEKernel)
#+END_CENTER

#+ATTR_LATEX: :width 1.1\textwidth
[[./SEKernel2.pdf]]


** Real data, splines model

#+ATTR_LATEX: :width .9\textwidth
[[./hist.pdf]]
\vfill


** Not perfect, but good enough
   :PROPERTIES:
   :BEAMER_opt: plain
   :END:
   
***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
#+ATTR_LATEX: :width 1.1\textwidth
[[./barsbad3.pdf]]

***  :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
    
#+ATTR_LATEX: :width 1.1\textwidth
[[./barsbad2.pdf]]


** Splines caveats
#+ATTR_LATEX: :overlay [<+->]
   * BARS works well, without any hyperparameter tuning
   * ISSUE: I don't know how or why it works
     * Can't rigorously justify why it's a good method
     * Can't predict when it would work and when it would fail
     * Can't determine good hyperparameter values
   * ISSUE: haven't implemented it
     * Relying on some old /C/ code to make it run
     * /C/ implementation evaluates the splines model at the training points, and returns them
     * Can't evaluate model at non-training points; doesn't give a continuous (interpolating) model, /can't be validated!/
   * ISSUE: harder to encode periodicity
     * Periodic kernels almost surely (probability 1) give periodic posteriors
     * Periodic splines are a thing, maybe try periodic BARS?
       

* Other ideas
** Abandoned ideas
   * Generalised spectral mixture kernels
     * Couldn't get them to train
       
\vfill
   * Support vector regression
     * Couldn't find any justification to use this over GPR
       
\vfill
   * Latent ODEs / neural ODEs / physics-informed NNs
     * Would require state-space reconstruction, doesn't seem like a beneficial use of time


** Other models for a paper
  * NARMAX
  * Wavelets
  * Warping GPs
    * Either learn a warp...
    * ...or apply a simple transformation to the data (log, exp, logistic, ...)
  * Deep GPs
  * Hybrid methods
  * Other nonparametric methods
    * RKHS, KNN, etc.


* Next steps
** Next steps
#+ATTR_LATEX: :overlay [<+->]
   * Dig into free-knot splines literature
     * BARS and other free-knot methods
   * Understand how and why it works
     * Useful for justifying why it's a good model, and when it will and won't work
     * Will help decide whether periodic BARS is possible
   * Write up my own implementation
     * Allows for validation, interplation 

Then...
#+ATTR_LATEX: :overlay [<+->]
   * Other data sources
   * Warping GPs, deep GPs, NARMAX, etc.
   * MATLAB wrapper?
     * Having ready-to-go codes might make a paper more popular

     
* GPR tests

#+BEGIN_SRC bash
./model_tester.py -d HRFast -m MySEKernel

./model_tester.py -d HindmarshRose -m Matern32 -p CleanFitted 
                  -r 1e-6 -V

./model_tester.py -d FitzhughNagumo -m ModuloKernel -r 1e-6 
                  -n 0.1

./model_tester.py -d HodgkinHuxley -m PeriodicKernel -o

./model_tester.py -d 08o28004_channel_0_sweep_8.np -m 
                  MySEKernel -f 6.23e2 -l 5.71e-8 -n 0.1
#+END_SRC
   


* COMMENT NOTES
  * The GPR testing code and why supervisors might enjoy playing with it
  * Experimental data
  * Matern kernel - why should it be a sensible choice?
  * The link between splines and GPR
  * Splines - why should it be a sensible choice?
  * Splines demo, with and without noise
  * Caveats with splines
  * When to use splines and when to use GPR
  * Other kernels that I could do but decided against
    * Nonstationary spectral kernel - should be a sensible choice but it didn't work
  * Other models that would be nice to discuss in a paper
  * Next steps


* COMMENT GPR test suite
   * Has several data sources coded in. Can choose one with -d --data; options are
     * FitzhughNagumo
     * HodgkinHuxley
     * HindmarshRose
     * HRFast
   * If the specified data source isn't one of those, it'll assume it's a datafile and use that instead
   * Coded data sources are simulated. To get more (or fewer!) datapoints, you can change the absolute error tolerance of the solver with -a --atol, and relative tolerance with -r --rtol (the latter being more useful)
   * A lot of data models are coded up; choose with -m --model one of the following:
     * gsm
     * sm
     * rbf
     * neural
     * SVR
     * FKL
     * MySEKernel
     * ModuloKernel
     * PeriodicKernel
     * Matern32
     * PeriodicMatern32
     * Matern52
     * BARS
   * If a model is not specified, it'll assume we're only wanting to visualise the data, and give a plot of the time series
   * Has fitted hyperparameters for most models; Can choose which set with the -p --hypers flag:
     * Noise-fitted
     * Clean-fitted
   * Can override fitted hyperpars with -l --lengthscale, -f --sigmaf, -P --period
   * Can add noise with -n --noise
   * Can optimise a model with -o --optimize
   * Can integrate out transients with -t --transients [TIME]
   * Can save simulated data to a .mat file with -s --save
   * Can partition data into test and training, and test the model's MSPE, rMSPE, with the -v --validate flag
   * Can choose how many points to evaluate the latent model at with -T --tests [NPOINTS]
   * For FKL, can choose how many training iterations to do with -i --niters [N ITERATIONS]
   * Can choose to down-sample data (eg. for large amounts of experimental data) using -D --downsample [N_SKIPS]. Retains 1/[N_SKIPS] of the data.
   * Can plot the variance bands with -V --var

     
